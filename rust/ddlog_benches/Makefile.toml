# Runs all ddlog benchmarks
[tasks.benchmark-all]
script_runner = "@duckscript"
script = """
time = current_time
mv target/criterion benchmarks/${time}-criterion
"""
dependencies = ["download-data", "bench-citations"]

# Runs the benchmark suite on the citations bench case
[tasks.bench-citations]
command = "cargo"
args = ["bench"]
dependencies = ["build-citations"]
private = true

# Runs `ddlog` on the citations bench case to generate code
[tasks.build-citations]
command = "ddlog"
args = [
    "-i",
    "ddlog/citations.dl",
    "--output-dir",
    "generated",
    "--nested-ts-32",
    "--omit-profile",
    "--omit-workspace",
]
dependencies = ["clean-citations"]
private = true

# Remove the old generated code (prevents OS errors and errors that
# occur when switching between different versions of ddlog that each
# generated & depend on different generated files)
#
# Note: This is by *no* means a bottleneck or slowdown, the benchmarks
# themselves take *vastly* more time to run
[tasks.clean-citations]
script_runner = "@duckscript"
script = """
rm -rf generated/citations_ddlog
"""
private = true

[tasks.download-data]
script_runner = "@duckscript"
script = """
fn <scope> download_file
    file = set ${1}
    url = set ${2}

    if not is_path_exists data/${file}
        echo downloading '${url}' to 'data/${file}'

        start_time = current_time
        wget -O data/${file} ${url}
        end_time = current_time

        millis = calc ${end_time} - ${start_time}
        sec = calc ${millis} / 1000
        echo downloaded 'data/${file}' in ${sec}sec
    else
        echo '${file}' has already been downloaded, skipping
    end
end

download_file twitter-2010-ids.csv.gz https://snap.stanford.edu/data/twitter-2010-ids.csv.gz
download_file soc-LiveJournal1.txt.gz https://snap.stanford.edu/data/soc-LiveJournal1.txt.gz
"""
